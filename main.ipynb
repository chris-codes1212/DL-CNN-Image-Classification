{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network: Colorectal Histology Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 4000\n",
      "Number of testing samples: 1000\n",
      "Dataset info: tfds.core.DatasetInfo(\n",
      "    name='colorectal_histology',\n",
      "    full_name='colorectal_histology/2.0.0',\n",
      "    description=\"\"\"\n",
      "    Classification of textures in colorectal cancer histology. Each example is a 150 x 150 x 3 RGB image of one of 8 classes.\n",
      "    \"\"\",\n",
      "    homepage='https://zenodo.org/record/53169#.XGZemKwzbmG',\n",
      "    data_dir='/home/ubuntu/tensorflow_datasets/colorectal_histology/2.0.0',\n",
      "    file_format=tfrecord,\n",
      "    download_size=246.14 MiB,\n",
      "    dataset_size=179.23 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'filename': Text(shape=(), dtype=string),\n",
      "        'image': Image(shape=(150, 150, 3), dtype=uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=8),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'train': <SplitInfo num_examples=5000, num_shards=2>,\n",
      "    },\n",
      "    citation=\"\"\"@article{kather2016multi,\n",
      "      title={Multi-class texture analysis in colorectal cancer histology},\n",
      "      author={Kather, Jakob Nikolas and Weis, Cleo-Aron and Bianconi, Francesco and Melchers, Susanne M and Schad, Lothar R and Gaiser, Timo and Marx, Alexander and Z{\"o}llner, Frank Gerrit},\n",
      "      journal={Scientific reports},\n",
      "      volume={6},\n",
      "      pages={27988},\n",
      "      year={2016},\n",
      "      publisher={Nature Publishing Group}\n",
      "    }\"\"\",\n",
      ")\n",
      "Image shape: (150, 150, 3), Label: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 18:45:49.446783: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Load the ColorectalHistology dataset\n",
    "# The dataset typically comes with a 'train' split.\n",
    "# We can use TFDS's slicing API to further split this 'train' split\n",
    "# into custom train and test sets.\n",
    "(train_ds, test_ds), ds_info = tfds.load(\n",
    "    'colorectal_histology',\n",
    "    split=['train[:80%]', 'train[80%:]'],  # 80% for training, 20% for testing\n",
    "    shuffle_files=True,  # Shuffle files before splitting\n",
    "    as_supervised=True,  # Return (image, label) pairs\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "# ds_info contains metadata about the dataset\n",
    "print(f\"Number of training samples: {len(train_ds)}\")\n",
    "print(f\"Number of testing samples: {len(test_ds)}\")\n",
    "print(f\"Dataset info: {ds_info}\")\n",
    "\n",
    "# You can now iterate over train_ds and test_ds\n",
    "# for example, to get a batch of data:\n",
    "for image, label in train_ds.take(1):\n",
    "    print(f\"Image shape: {image.shape}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 3), 4\n",
      "(150, 150, 3), 5\n",
      "(150, 150, 3), 6\n",
      "<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 18:45:49.608691: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_ds.take(3):\n",
    "    print(f\"{image.shape}, {label}\")\n",
    "\n",
    "#normalize images\n",
    "print(type(train_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert image data into tensors where each pixel value is a float that is normalized (between [0-1]) across all color channels\n",
    "def preprocess_image(image, label):\n",
    "    # Convert image to float32 and scale to [0, 1]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    \n",
    "    # Optional: data augmentation\n",
    "    # image = tf.image.random_flip_left_right(image)\n",
    "    # image = tf.image.random_brightness(image, 0.1)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 150, 150, 3) (32,)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 18:45:50.370151: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data \n",
    "\n",
    "# map current values in the tensor to normalized float32 values for both train and test datasets\n",
    "train_ds = train_ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "test_ds = test_ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# shuffle the training set, created batches of images for training, and set prefetch to AUTOTUNE for tf to optimize image data management \n",
    "# during training\n",
    "train_ds = train_ds.shuffle(buffer_size=1000) \\\n",
    "                   .batch(32) \\\n",
    "                   .prefetch(AUTOTUNE)\n",
    "# just need to create batches of test data, no need to shuffle\n",
    "test_ds = test_ds.batch(32).prefetch(AUTOTUNE)\n",
    "\n",
    "# get the shape of our new traning data and make sure values in image tensors are between (0,1)\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(images.shape, labels.shape)\n",
    "    print(tf.reduce_min(images), tf.reduce_max(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
